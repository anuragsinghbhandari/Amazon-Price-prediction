{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26e9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641e1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6773853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n",
      "TF-IDF shape: (75000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizing text...\")\n",
    "\n",
    "# load the vectorizer\n",
    "tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# transform new text data (no need to fit again)\n",
    "X_new = tfidf.transform(df['catalog_content'])\n",
    "\n",
    "\n",
    "print(\"TF-IDF shape:\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da48868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached text embeddings\n",
      "Text embeddings shape: (75000, 384)\n"
     ]
    }
   ],
   "source": [
    "text_embeddings_file = \"test_text_embeddings.npy\"\n",
    "\n",
    "# Check if cached embeddings exist\n",
    "try:\n",
    "    text_embeddings = np.load(text_embeddings_file)\n",
    "    print(\"Loaded cached text embeddings\")\n",
    "except:\n",
    "    text_model = SentenceTransformer('all-MiniLM-L6-v2')  # small & fast\n",
    "    print(\"Encoding text with BERT...\")\n",
    "    text_embeddings = text_model.encode(df['catalog_content'].tolist(), show_progress_bar=True)\n",
    "    np.save(text_embeddings_file, text_embeddings)\n",
    "    print(\"Text embeddings saved\")\n",
    "\n",
    "print(\"Text embeddings shape:\", text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605c0463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       numeric_value unit_extracted  standardized_value standardized_unit  \\\n",
      "0               10.5          Ounce           297.67500                 g   \n",
      "1                2.0          Fl Oz            59.14700                mL   \n",
      "2               32.0          Ounce           907.20000                 g   \n",
      "3                2.0          Count             2.00000             count   \n",
      "4               32.0          Fl Oz           946.35200                mL   \n",
      "...              ...            ...                 ...               ...   \n",
      "74995            2.4          Ounce            68.04000                 g   \n",
      "74996            7.0          Ounce           198.45000                 g   \n",
      "74997           11.5          Fl Oz           340.09525                mL   \n",
      "74998           16.0          Ounce           453.60000                 g   \n",
      "74999           64.8          Ounce          1837.08000                 g   \n",
      "\n",
      "      unit_type  \n",
      "0        weight  \n",
      "1        volume  \n",
      "2        weight  \n",
      "3         count  \n",
      "4        volume  \n",
      "...         ...  \n",
      "74995    weight  \n",
      "74996    weight  \n",
      "74997    volume  \n",
      "74998    weight  \n",
      "74999    weight  \n",
      "\n",
      "[75000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: extract numeric + unit\n",
    "def extract_value_and_unit(text):\n",
    "    value_match = re.search(r\"Value:\\s*([\\d\\.]+)\", text)\n",
    "    value = float(value_match.group(1)) if value_match else None\n",
    "    \n",
    "    unit_match = re.search(r\"Unit:\\s*([A-Za-z ]+)\", text)\n",
    "    unit = unit_match.group(1).strip() if unit_match else None\n",
    "    \n",
    "    return pd.Series([value, unit])\n",
    "\n",
    "df[[\"numeric_value\", \"unit_extracted\"]] = df[\"catalog_content\"].apply(extract_value_and_unit)\n",
    "\n",
    "# Step 2: normalize units\n",
    "def normalize_units(value, unit):\n",
    "    if pd.isna(unit) or pd.isna(value):\n",
    "        return pd.Series([value, unit, \"unknown\"])\n",
    "    \n",
    "    u = unit.strip().lower()\n",
    "    \n",
    "    # Weight conversions to grams\n",
    "    if u in [\"ounce\", \"oz\", \"ounces\"]:\n",
    "        return pd.Series([value * 28.35, \"g\", \"weight\"])\n",
    "    elif u in [\"pound\", \"lb\", \"lbs\"]:\n",
    "        return pd.Series([value * 453.592, \"g\", \"weight\"])\n",
    "    \n",
    "    # Volume conversions to milliliters\n",
    "    elif u in [\"fl oz\", \"floz\", \"fluid ounce\", \"fluid ounces\", \"Fl Ounce\"]:\n",
    "        return pd.Series([value * 29.5735, \"mL\", \"volume\"])\n",
    "    elif u in [\"liter\", \"litre\", \"l\",\"ltr\"]:\n",
    "        return pd.Series([value * 1000, \"mL\", \"volume\"])\n",
    "    \n",
    "    # Count-based (no conversion)\n",
    "    elif u in [\"count\", \"pack\", \"pcs\", \"piece\", \"pieces\", \"PACK\", \"can\", \"Carton\", \"Tea bags\"]:\n",
    "        return pd.Series([value, \"count\", \"count\"])\n",
    "    \n",
    "    # Unknown\n",
    "    else:\n",
    "        return pd.Series([value, unit, \"unknown\"])\n",
    "\n",
    "df[[\"standardized_value\", \"standardized_unit\", \"unit_type\"]] = df.apply(\n",
    "    lambda x: normalize_units(x[\"numeric_value\"], x[\"unit_extracted\"]), axis=1\n",
    ")\n",
    "\n",
    "print(df[[\"numeric_value\", \"unit_extracted\", \"standardized_value\", \"standardized_unit\", \"unit_type\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c95f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = joblib.load('labelencoder.pkl')\n",
    "\n",
    "categorical_cols = [\"unit_type\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    \n",
    "    df[col] = le.transform(df[col].astype(str))\n",
    "\n",
    "new_feature = df[['standardized_value','unit_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c87cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced TF-IDF shape: (75000, 256)\n",
      "Final combined feature shape: (75000, 642)\n"
     ]
    }
   ],
   "source": [
    "# Suppose X_tfidf is your TF-IDF matrix: (n_samples, 10000)\n",
    "svd = joblib.load('svd_transformer.pkl')\n",
    "\n",
    "X_tfidf_reduced = svd.transform(X_new)\n",
    "print(\"Reduced TF-IDF shape:\", X_tfidf_reduced.shape)\n",
    "\n",
    "# Scale TF-IDF reduced\n",
    "scaler_tfidf = joblib.load('scaler_tfidf.pkl')\n",
    "X_tfidf_scaled = scaler_tfidf.transform(X_tfidf_reduced)\n",
    "\n",
    "# Scale BERT embeddings (dense)\n",
    "scaler_bert = joblib.load('scaler_bert.pkl')\n",
    "X_bert_scaled = scaler_bert.transform(text_embeddings)\n",
    "\n",
    "\n",
    "# Combine all features\n",
    "X_combined = np.hstack([X_tfidf_reduced, text_embeddings, new_feature])\n",
    "\n",
    "print(\"Final combined feature shape:\", X_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf562964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.Booster(model_file='lgbm_model.txt')\n",
    "predictions = np.expm1(model.predict(X_combined))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd6c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to test_out.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'sample_id': df['sample_id'],\n",
    "    'price': predictions        # predicted values\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('test_out.csv', index=False)\n",
    "\n",
    "print(\"Saved to test_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431719ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
